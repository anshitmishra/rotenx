{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d99aa7c-5264-4235-8be0-6a2aa05e300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f36fbea-66ea-4378-a452-1cf6b7c1dbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EMG_A0</th>\n",
       "      <th>EMG_A1</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1.707697e+09</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Timestamp  EMG_A0  EMG_A1 Label\n",
       "0    1.707697e+09      25       0     b\n",
       "1    1.707697e+09      25      33     b\n",
       "2    1.707697e+09      23       0     b\n",
       "3    1.707697e+09      23       0     b\n",
       "4    1.707697e+09      25       0     b\n",
       "..            ...     ...     ...   ...\n",
       "583  1.707697e+09     109       0     d\n",
       "584  1.707697e+09     109       0     d\n",
       "585  1.707697e+09     117       0     d\n",
       "586  1.707697e+09     102       0     d\n",
       "587  1.707697e+09     107       0     d\n",
       "\n",
       "[588 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the EMG data from the Excel file\n",
    "emg_data = pd.read_excel('emg_data.xlsx')\n",
    "\n",
    "# Drop rows with missing values (NaN)\n",
    "emg_data = emg_data.dropna()\n",
    "emg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24389129-23e3-49cc-abba-527fb6f12941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emg_data[['EMG_A0', 'EMG_A1']].values\n",
    "y_str = emg_data['Label'].values\n",
    "\n",
    "\n",
    "# Use LabelEncoder to convert string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "600226e6-86a6-46db-b98e-0360034a92ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,) (470,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(y_test.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c1315c-c643-4048-9b8d-ef6655f88240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2901bca0-5e48-42a0-9184-57034decf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for LSTM input (samples, time steps, features)\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "135f6058-d013-46e8-9374-ae0176a389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification (adjust for your problem)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a312cd76-82bc-4010-8664-8a482907df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 3s 43ms/step - loss: 0.8947 - accuracy: 0.2043 - val_loss: 0.6617 - val_accuracy: 0.3475\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.3319 - val_loss: 0.6272 - val_accuracy: 0.1610\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.3319 - val_loss: 0.5939 - val_accuracy: 0.1017\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: -0.3183 - accuracy: 0.3319 - val_loss: 0.5618 - val_accuracy: 0.0932\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: -0.7068 - accuracy: 0.3319 - val_loss: 0.5305 - val_accuracy: 0.0847\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: -1.1694 - accuracy: 0.3319 - val_loss: 0.5026 - val_accuracy: 0.0847\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: -1.7160 - accuracy: 0.3319 - val_loss: 0.4761 - val_accuracy: 0.0847\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: -2.1725 - accuracy: 0.3319 - val_loss: 0.4533 - val_accuracy: 0.0847\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 5ms/step - loss: -2.4505 - accuracy: 0.3319 - val_loss: 0.4318 - val_accuracy: 0.0847\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: -2.6782 - accuracy: 0.3319 - val_loss: 0.4125 - val_accuracy: 0.0847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2904fafe1a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_data=(X_test_reshaped, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e778111e-27a4-4040-8677-cdc19a855dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.0847\n",
      "Test Loss: 0.4124651551246643, Test Accuracy: 0.08474576473236084\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ae1c807-b2f9-43d0-8323-309ed765f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as emg_label_prediction_model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('emg_label_prediction_model.h5')\n",
    "print('Model saved as emg_label_prediction_model.h5')\n",
    "\n",
    "# Save label encoder for future use\n",
    "import joblib\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73177f8a-1ab9-434f-8346-57b9108c1154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db3ab283-0179-466c-a1cb-1c1ca58cdfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 682ms/step - loss: 0.7023 - accuracy: 0.4688 - val_loss: 0.7044 - val_accuracy: 0.4375\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7000 - accuracy: 0.4688 - val_loss: 0.6999 - val_accuracy: 0.4375\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6962 - accuracy: 0.4688 - val_loss: 0.6963 - val_accuracy: 0.4375\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5625\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6910 - val_accuracy: 0.5625\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6908 - accuracy: 0.5312 - val_loss: 0.6895 - val_accuracy: 0.5625\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6911 - accuracy: 0.5312 - val_loss: 0.6882 - val_accuracy: 0.5625\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6908 - accuracy: 0.5312 - val_loss: 0.6874 - val_accuracy: 0.5625\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6911 - accuracy: 0.5312 - val_loss: 0.6869 - val_accuracy: 0.5625\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6918 - accuracy: 0.5312 - val_loss: 0.6866 - val_accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7075 - accuracy: 0.4500\n",
      "Test Loss: 0.7075080871582031, Test Accuracy: 0.44999998807907104\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "Predicted Probability: 0.438807874917984\n",
      "Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.random((100, 10, 1))  # Sample input data with shape (samples, timesteps, features)\n",
    "y = np.random.randint(0, 2, size=(100,))  # Binary labels (0 or 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions on a new test case (adjust as per your actual data)\n",
    "new_test_case = np.random.random((1, 10, 1\n",
    "                                 \n",
    "prediction = model.predict(new_test_case)\n",
    "\n",
    "print(f'Predicted Probability: {prediction[0][0]}')\n",
    "predicted_label = 1 if prediction[0][0] > 0.5 else 0\n",
    "print(f'Predicted Label: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3eb983b-cfb6-4150-a488-9f764f2b80c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.37454012],\n",
       "        [0.95071431],\n",
       "        [0.73199394],\n",
       "        [0.59865848],\n",
       "        [0.15601864],\n",
       "        [0.15599452],\n",
       "        [0.05808361],\n",
       "        [0.86617615],\n",
       "        [0.60111501],\n",
       "        [0.70807258]],\n",
       "\n",
       "       [[0.02058449],\n",
       "        [0.96990985],\n",
       "        [0.83244264],\n",
       "        [0.21233911],\n",
       "        [0.18182497],\n",
       "        [0.18340451],\n",
       "        [0.30424224],\n",
       "        [0.52475643],\n",
       "        [0.43194502],\n",
       "        [0.29122914]],\n",
       "\n",
       "       [[0.61185289],\n",
       "        [0.13949386],\n",
       "        [0.29214465],\n",
       "        [0.36636184],\n",
       "        [0.45606998],\n",
       "        [0.78517596],\n",
       "        [0.19967378],\n",
       "        [0.51423444],\n",
       "        [0.59241457],\n",
       "        [0.04645041]],\n",
       "\n",
       "       [[0.60754485],\n",
       "        [0.17052412],\n",
       "        [0.06505159],\n",
       "        [0.94888554],\n",
       "        [0.96563203],\n",
       "        [0.80839735],\n",
       "        [0.30461377],\n",
       "        [0.09767211],\n",
       "        [0.68423303],\n",
       "        [0.44015249]],\n",
       "\n",
       "       [[0.12203823],\n",
       "        [0.49517691],\n",
       "        [0.03438852],\n",
       "        [0.9093204 ],\n",
       "        [0.25877998],\n",
       "        [0.66252228],\n",
       "        [0.31171108],\n",
       "        [0.52006802],\n",
       "        [0.54671028],\n",
       "        [0.18485446]],\n",
       "\n",
       "       [[0.96958463],\n",
       "        [0.77513282],\n",
       "        [0.93949894],\n",
       "        [0.89482735],\n",
       "        [0.59789998],\n",
       "        [0.92187424],\n",
       "        [0.0884925 ],\n",
       "        [0.19598286],\n",
       "        [0.04522729],\n",
       "        [0.32533033]],\n",
       "\n",
       "       [[0.38867729],\n",
       "        [0.27134903],\n",
       "        [0.82873751],\n",
       "        [0.35675333],\n",
       "        [0.28093451],\n",
       "        [0.54269608],\n",
       "        [0.14092422],\n",
       "        [0.80219698],\n",
       "        [0.07455064],\n",
       "        [0.98688694]],\n",
       "\n",
       "       [[0.77224477],\n",
       "        [0.19871568],\n",
       "        [0.00552212],\n",
       "        [0.81546143],\n",
       "        [0.70685734],\n",
       "        [0.72900717],\n",
       "        [0.77127035],\n",
       "        [0.07404465],\n",
       "        [0.35846573],\n",
       "        [0.11586906]],\n",
       "\n",
       "       [[0.86310343],\n",
       "        [0.62329813],\n",
       "        [0.33089802],\n",
       "        [0.06355835],\n",
       "        [0.31098232],\n",
       "        [0.32518332],\n",
       "        [0.72960618],\n",
       "        [0.63755747],\n",
       "        [0.88721274],\n",
       "        [0.47221493]],\n",
       "\n",
       "       [[0.11959425],\n",
       "        [0.71324479],\n",
       "        [0.76078505],\n",
       "        [0.5612772 ],\n",
       "        [0.77096718],\n",
       "        [0.4937956 ],\n",
       "        [0.52273283],\n",
       "        [0.42754102],\n",
       "        [0.02541913],\n",
       "        [0.10789143]],\n",
       "\n",
       "       [[0.03142919],\n",
       "        [0.63641041],\n",
       "        [0.31435598],\n",
       "        [0.50857069],\n",
       "        [0.90756647],\n",
       "        [0.24929223],\n",
       "        [0.41038292],\n",
       "        [0.75555114],\n",
       "        [0.22879817],\n",
       "        [0.07697991]],\n",
       "\n",
       "       [[0.28975145],\n",
       "        [0.16122129],\n",
       "        [0.92969765],\n",
       "        [0.80812038],\n",
       "        [0.63340376],\n",
       "        [0.87146059],\n",
       "        [0.80367208],\n",
       "        [0.18657006],\n",
       "        [0.892559  ],\n",
       "        [0.53934224]],\n",
       "\n",
       "       [[0.80744016],\n",
       "        [0.8960913 ],\n",
       "        [0.31800347],\n",
       "        [0.11005192],\n",
       "        [0.22793516],\n",
       "        [0.42710779],\n",
       "        [0.81801477],\n",
       "        [0.86073058],\n",
       "        [0.00695213],\n",
       "        [0.5107473 ]],\n",
       "\n",
       "       [[0.417411  ],\n",
       "        [0.22210781],\n",
       "        [0.11986537],\n",
       "        [0.33761517],\n",
       "        [0.9429097 ],\n",
       "        [0.32320293],\n",
       "        [0.51879062],\n",
       "        [0.70301896],\n",
       "        [0.3636296 ],\n",
       "        [0.97178208]],\n",
       "\n",
       "       [[0.96244729],\n",
       "        [0.2517823 ],\n",
       "        [0.49724851],\n",
       "        [0.30087831],\n",
       "        [0.28484049],\n",
       "        [0.03688695],\n",
       "        [0.60956433],\n",
       "        [0.50267902],\n",
       "        [0.05147875],\n",
       "        [0.27864646]],\n",
       "\n",
       "       [[0.90826589],\n",
       "        [0.23956189],\n",
       "        [0.14489487],\n",
       "        [0.48945276],\n",
       "        [0.98565045],\n",
       "        [0.24205527],\n",
       "        [0.67213555],\n",
       "        [0.76161962],\n",
       "        [0.23763754],\n",
       "        [0.72821635]],\n",
       "\n",
       "       [[0.36778313],\n",
       "        [0.63230583],\n",
       "        [0.63352971],\n",
       "        [0.53577468],\n",
       "        [0.09028977],\n",
       "        [0.8353025 ],\n",
       "        [0.32078006],\n",
       "        [0.18651851],\n",
       "        [0.04077514],\n",
       "        [0.59089294]],\n",
       "\n",
       "       [[0.67756436],\n",
       "        [0.01658783],\n",
       "        [0.51209306],\n",
       "        [0.22649578],\n",
       "        [0.64517279],\n",
       "        [0.17436643],\n",
       "        [0.69093774],\n",
       "        [0.38673535],\n",
       "        [0.93672999],\n",
       "        [0.13752094]],\n",
       "\n",
       "       [[0.34106635],\n",
       "        [0.11347352],\n",
       "        [0.92469362],\n",
       "        [0.87733935],\n",
       "        [0.25794163],\n",
       "        [0.65998405],\n",
       "        [0.8172222 ],\n",
       "        [0.55520081],\n",
       "        [0.52965058],\n",
       "        [0.24185229]],\n",
       "\n",
       "       [[0.09310277],\n",
       "        [0.89721576],\n",
       "        [0.90041806],\n",
       "        [0.63310146],\n",
       "        [0.33902979],\n",
       "        [0.34920957],\n",
       "        [0.72595568],\n",
       "        [0.89711026],\n",
       "        [0.88708642],\n",
       "        [0.77987555]],\n",
       "\n",
       "       [[0.64203165],\n",
       "        [0.08413996],\n",
       "        [0.16162871],\n",
       "        [0.89855419],\n",
       "        [0.60642906],\n",
       "        [0.00919705],\n",
       "        [0.10147154],\n",
       "        [0.66350177],\n",
       "        [0.00506158],\n",
       "        [0.16080805]],\n",
       "\n",
       "       [[0.54873379],\n",
       "        [0.6918952 ],\n",
       "        [0.65196126],\n",
       "        [0.22426931],\n",
       "        [0.71217922],\n",
       "        [0.23724909],\n",
       "        [0.3253997 ],\n",
       "        [0.74649141],\n",
       "        [0.6496329 ],\n",
       "        [0.84922341]],\n",
       "\n",
       "       [[0.65761289],\n",
       "        [0.5683086 ],\n",
       "        [0.09367477],\n",
       "        [0.3677158 ],\n",
       "        [0.26520237],\n",
       "        [0.24398964],\n",
       "        [0.97301055],\n",
       "        [0.39309772],\n",
       "        [0.89204656],\n",
       "        [0.63113863]],\n",
       "\n",
       "       [[0.7948113 ],\n",
       "        [0.50263709],\n",
       "        [0.57690388],\n",
       "        [0.49251769],\n",
       "        [0.19524299],\n",
       "        [0.72245212],\n",
       "        [0.28077236],\n",
       "        [0.02431597],\n",
       "        [0.6454723 ],\n",
       "        [0.17711068]],\n",
       "\n",
       "       [[0.94045858],\n",
       "        [0.95392858],\n",
       "        [0.91486439],\n",
       "        [0.3701587 ],\n",
       "        [0.01545662],\n",
       "        [0.92831856],\n",
       "        [0.42818415],\n",
       "        [0.96665482],\n",
       "        [0.96361998],\n",
       "        [0.85300946]],\n",
       "\n",
       "       [[0.29444889],\n",
       "        [0.38509773],\n",
       "        [0.85113667],\n",
       "        [0.31692201],\n",
       "        [0.16949275],\n",
       "        [0.55680126],\n",
       "        [0.93615477],\n",
       "        [0.6960298 ],\n",
       "        [0.57006117],\n",
       "        [0.09717649]],\n",
       "\n",
       "       [[0.61500723],\n",
       "        [0.99005385],\n",
       "        [0.14008402],\n",
       "        [0.51832965],\n",
       "        [0.87737307],\n",
       "        [0.74076862],\n",
       "        [0.69701574],\n",
       "        [0.70248408],\n",
       "        [0.35949115],\n",
       "        [0.29359184]],\n",
       "\n",
       "       [[0.80936116],\n",
       "        [0.81011339],\n",
       "        [0.86707232],\n",
       "        [0.91324055],\n",
       "        [0.5113424 ],\n",
       "        [0.50151629],\n",
       "        [0.79829518],\n",
       "        [0.64996393],\n",
       "        [0.70196688],\n",
       "        [0.79579267]],\n",
       "\n",
       "       [[0.89000534],\n",
       "        [0.33799516],\n",
       "        [0.37558295],\n",
       "        [0.09398194],\n",
       "        [0.57828014],\n",
       "        [0.03594227],\n",
       "        [0.46559802],\n",
       "        [0.54264463],\n",
       "        [0.28654125],\n",
       "        [0.59083326]],\n",
       "\n",
       "       [[0.03050025],\n",
       "        [0.03734819],\n",
       "        [0.82260056],\n",
       "        [0.36019064],\n",
       "        [0.12706051],\n",
       "        [0.52224326],\n",
       "        [0.76999355],\n",
       "        [0.21582103],\n",
       "        [0.62289048],\n",
       "        [0.08534746]],\n",
       "\n",
       "       [[0.05168172],\n",
       "        [0.53135463],\n",
       "        [0.54063512],\n",
       "        [0.6374299 ],\n",
       "        [0.72609133],\n",
       "        [0.97585208],\n",
       "        [0.51630035],\n",
       "        [0.32295647],\n",
       "        [0.79518619],\n",
       "        [0.27083225]],\n",
       "\n",
       "       [[0.43897142],\n",
       "        [0.07845638],\n",
       "        [0.02535074],\n",
       "        [0.96264841],\n",
       "        [0.83598012],\n",
       "        [0.69597421],\n",
       "        [0.40895294],\n",
       "        [0.17329432],\n",
       "        [0.15643704],\n",
       "        [0.2502429 ]],\n",
       "\n",
       "       [[0.54922666],\n",
       "        [0.71459592],\n",
       "        [0.66019738],\n",
       "        [0.2799339 ],\n",
       "        [0.95486528],\n",
       "        [0.73789692],\n",
       "        [0.55435405],\n",
       "        [0.61172075],\n",
       "        [0.41960006],\n",
       "        [0.24773099]],\n",
       "\n",
       "       [[0.35597268],\n",
       "        [0.75784611],\n",
       "        [0.01439349],\n",
       "        [0.11607264],\n",
       "        [0.04600264],\n",
       "        [0.0407288 ],\n",
       "        [0.85546058],\n",
       "        [0.70365786],\n",
       "        [0.47417383],\n",
       "        [0.09783416]],\n",
       "\n",
       "       [[0.49161588],\n",
       "        [0.47347177],\n",
       "        [0.17320187],\n",
       "        [0.43385165],\n",
       "        [0.39850473],\n",
       "        [0.6158501 ],\n",
       "        [0.63509365],\n",
       "        [0.04530401],\n",
       "        [0.37461261],\n",
       "        [0.62585992]],\n",
       "\n",
       "       [[0.50313626],\n",
       "        [0.85648984],\n",
       "        [0.65869363],\n",
       "        [0.16293443],\n",
       "        [0.07056875],\n",
       "        [0.64241928],\n",
       "        [0.02651131],\n",
       "        [0.58577558],\n",
       "        [0.94023024],\n",
       "        [0.57547418]],\n",
       "\n",
       "       [[0.38816993],\n",
       "        [0.64328822],\n",
       "        [0.45825289],\n",
       "        [0.54561679],\n",
       "        [0.94146481],\n",
       "        [0.38610264],\n",
       "        [0.96119056],\n",
       "        [0.90535064],\n",
       "        [0.19579113],\n",
       "        [0.0693613 ]],\n",
       "\n",
       "       [[0.100778  ],\n",
       "        [0.01822183],\n",
       "        [0.09444296],\n",
       "        [0.68300677],\n",
       "        [0.07118865],\n",
       "        [0.31897563],\n",
       "        [0.84487531],\n",
       "        [0.02327194],\n",
       "        [0.81446848],\n",
       "        [0.28185477]],\n",
       "\n",
       "       [[0.11816483],\n",
       "        [0.69673717],\n",
       "        [0.62894285],\n",
       "        [0.87747201],\n",
       "        [0.73507104],\n",
       "        [0.80348093],\n",
       "        [0.28203457],\n",
       "        [0.17743954],\n",
       "        [0.75061475],\n",
       "        [0.80683474]],\n",
       "\n",
       "       [[0.99050514],\n",
       "        [0.41261768],\n",
       "        [0.37201809],\n",
       "        [0.77641296],\n",
       "        [0.34080354],\n",
       "        [0.93075733],\n",
       "        [0.85841275],\n",
       "        [0.42899403],\n",
       "        [0.75087107],\n",
       "        [0.75454287]],\n",
       "\n",
       "       [[0.10312387],\n",
       "        [0.90255291],\n",
       "        [0.50525237],\n",
       "        [0.82645747],\n",
       "        [0.3200496 ],\n",
       "        [0.89552323],\n",
       "        [0.38920168],\n",
       "        [0.01083765],\n",
       "        [0.90538198],\n",
       "        [0.09128668]],\n",
       "\n",
       "       [[0.31931364],\n",
       "        [0.95006197],\n",
       "        [0.95060715],\n",
       "        [0.57343789],\n",
       "        [0.63183721],\n",
       "        [0.44844552],\n",
       "        [0.29321077],\n",
       "        [0.32866455],\n",
       "        [0.67251846],\n",
       "        [0.75237453]],\n",
       "\n",
       "       [[0.79157904],\n",
       "        [0.78961814],\n",
       "        [0.0912061 ],\n",
       "        [0.4944203 ],\n",
       "        [0.05755876],\n",
       "        [0.54952888],\n",
       "        [0.4415305 ],\n",
       "        [0.88770418],\n",
       "        [0.35091501],\n",
       "        [0.11706702]],\n",
       "\n",
       "       [[0.14299168],\n",
       "        [0.76151063],\n",
       "        [0.61821806],\n",
       "        [0.10112268],\n",
       "        [0.08410681],\n",
       "        [0.70096913],\n",
       "        [0.07276301],\n",
       "        [0.82186006],\n",
       "        [0.70624223],\n",
       "        [0.08134878]],\n",
       "\n",
       "       [[0.08483771],\n",
       "        [0.98663958],\n",
       "        [0.3742708 ],\n",
       "        [0.37064215],\n",
       "        [0.81279957],\n",
       "        [0.94724858],\n",
       "        [0.98600106],\n",
       "        [0.75337819],\n",
       "        [0.37625959],\n",
       "        [0.08350072]],\n",
       "\n",
       "       [[0.77714692],\n",
       "        [0.55840425],\n",
       "        [0.42422201],\n",
       "        [0.90635439],\n",
       "        [0.11119748],\n",
       "        [0.4926251 ],\n",
       "        [0.01135364],\n",
       "        [0.46866064],\n",
       "        [0.05630328],\n",
       "        [0.11881792]],\n",
       "\n",
       "       [[0.11752625],\n",
       "        [0.6492103 ],\n",
       "        [0.74604488],\n",
       "        [0.58336877],\n",
       "        [0.96217255],\n",
       "        [0.37487058],\n",
       "        [0.28571209],\n",
       "        [0.86859913],\n",
       "        [0.22359584],\n",
       "        [0.96322254]],\n",
       "\n",
       "       [[0.01215447],\n",
       "        [0.96987883],\n",
       "        [0.04315991],\n",
       "        [0.89114311],\n",
       "        [0.52770111],\n",
       "        [0.9929648 ],\n",
       "        [0.07379656],\n",
       "        [0.55385428],\n",
       "        [0.96930254],\n",
       "        [0.52309784]],\n",
       "\n",
       "       [[0.62939864],\n",
       "        [0.69574869],\n",
       "        [0.45454106],\n",
       "        [0.62755808],\n",
       "        [0.58431431],\n",
       "        [0.90115801],\n",
       "        [0.04544638],\n",
       "        [0.28096319],\n",
       "        [0.95041148],\n",
       "        [0.89026378]],\n",
       "\n",
       "       [[0.45565675],\n",
       "        [0.6201326 ],\n",
       "        [0.27738118],\n",
       "        [0.18812116],\n",
       "        [0.4636984 ],\n",
       "        [0.35335223],\n",
       "        [0.58365611],\n",
       "        [0.07773464],\n",
       "        [0.97439481],\n",
       "        [0.98621074]],\n",
       "\n",
       "       [[0.69816171],\n",
       "        [0.53609637],\n",
       "        [0.30952762],\n",
       "        [0.81379502],\n",
       "        [0.68473117],\n",
       "        [0.16261694],\n",
       "        [0.91092718],\n",
       "        [0.82253724],\n",
       "        [0.94979991],\n",
       "        [0.72571951]],\n",
       "\n",
       "       [[0.6134152 ],\n",
       "        [0.41824304],\n",
       "        [0.93272848],\n",
       "        [0.86606389],\n",
       "        [0.04521867],\n",
       "        [0.02636697],\n",
       "        [0.37646337],\n",
       "        [0.81055333],\n",
       "        [0.98727613],\n",
       "        [0.15041689]],\n",
       "\n",
       "       [[0.59413072],\n",
       "        [0.38089086],\n",
       "        [0.9699144 ],\n",
       "        [0.84211892],\n",
       "        [0.8383287 ],\n",
       "        [0.46869316],\n",
       "        [0.4148195 ],\n",
       "        [0.27340707],\n",
       "        [0.0563755 ],\n",
       "        [0.86472238]],\n",
       "\n",
       "       [[0.81290101],\n",
       "        [0.99971767],\n",
       "        [0.99663684],\n",
       "        [0.55543171],\n",
       "        [0.76898742],\n",
       "        [0.94476573],\n",
       "        [0.84964739],\n",
       "        [0.2473481 ],\n",
       "        [0.45054414],\n",
       "        [0.12915942]],\n",
       "\n",
       "       [[0.95405103],\n",
       "        [0.60617463],\n",
       "        [0.22864281],\n",
       "        [0.67170068],\n",
       "        [0.61812824],\n",
       "        [0.35816272],\n",
       "        [0.11355759],\n",
       "        [0.6715732 ],\n",
       "        [0.5203077 ],\n",
       "        [0.77231839]],\n",
       "\n",
       "       [[0.5201635 ],\n",
       "        [0.8521815 ],\n",
       "        [0.55190684],\n",
       "        [0.56093797],\n",
       "        [0.8766536 ],\n",
       "        [0.40348287],\n",
       "        [0.13401523],\n",
       "        [0.02878268],\n",
       "        [0.75513726],\n",
       "        [0.62030955]],\n",
       "\n",
       "       [[0.70407977],\n",
       "        [0.21296416],\n",
       "        [0.13637148],\n",
       "        [0.01454467],\n",
       "        [0.35058756],\n",
       "        [0.58991769],\n",
       "        [0.39224405],\n",
       "        [0.43747492],\n",
       "        [0.90415869],\n",
       "        [0.34825547]],\n",
       "\n",
       "       [[0.51398949],\n",
       "        [0.78365301],\n",
       "        [0.39654278],\n",
       "        [0.6220867 ],\n",
       "        [0.86236371],\n",
       "        [0.94952062],\n",
       "        [0.14707348],\n",
       "        [0.92658763],\n",
       "        [0.49211629],\n",
       "        [0.25824439]],\n",
       "\n",
       "       [[0.45913576],\n",
       "        [0.98003258],\n",
       "        [0.49261809],\n",
       "        [0.32875161],\n",
       "        [0.63340085],\n",
       "        [0.24014562],\n",
       "        [0.07586333],\n",
       "        [0.12887972],\n",
       "        [0.12804584],\n",
       "        [0.15190269]],\n",
       "\n",
       "       [[0.13882717],\n",
       "        [0.64087474],\n",
       "        [0.18188008],\n",
       "        [0.34566728],\n",
       "        [0.89678841],\n",
       "        [0.47396164],\n",
       "        [0.66755774],\n",
       "        [0.17231987],\n",
       "        [0.19228902],\n",
       "        [0.04086862]],\n",
       "\n",
       "       [[0.16893506],\n",
       "        [0.27859034],\n",
       "        [0.17701048],\n",
       "        [0.08870253],\n",
       "        [0.12063587],\n",
       "        [0.46077877],\n",
       "        [0.20633372],\n",
       "        [0.36426986],\n",
       "        [0.50341727],\n",
       "        [0.69039483]],\n",
       "\n",
       "       [[0.03931214],\n",
       "        [0.7994104 ],\n",
       "        [0.62790039],\n",
       "        [0.08175903],\n",
       "        [0.87357862],\n",
       "        [0.9208724 ],\n",
       "        [0.06107796],\n",
       "        [0.27687765],\n",
       "        [0.80620128],\n",
       "        [0.74825969]],\n",
       "\n",
       "       [[0.18452102],\n",
       "        [0.20934932],\n",
       "        [0.3704721 ],\n",
       "        [0.48452299],\n",
       "        [0.61825477],\n",
       "        [0.36891364],\n",
       "        [0.46253472],\n",
       "        [0.74747094],\n",
       "        [0.0366832 ],\n",
       "        [0.25243694]],\n",
       "\n",
       "       [[0.71334959],\n",
       "        [0.89520684],\n",
       "        [0.51167744],\n",
       "        [0.53211349],\n",
       "        [0.10717201],\n",
       "        [0.44741237],\n",
       "        [0.53261727],\n",
       "        [0.2424705 ],\n",
       "        [0.26924323],\n",
       "        [0.37728416]],\n",
       "\n",
       "       [[0.0200712 ],\n",
       "        [0.32207917],\n",
       "        [0.21144801],\n",
       "        [0.32749735],\n",
       "        [0.11976213],\n",
       "        [0.89052728],\n",
       "        [0.59359245],\n",
       "        [0.67910232],\n",
       "        [0.78917124],\n",
       "        [0.4984422 ]],\n",
       "\n",
       "       [[0.08692029],\n",
       "        [0.53710654],\n",
       "        [0.58684112],\n",
       "        [0.74543947],\n",
       "        [0.43165955],\n",
       "        [0.1275803 ],\n",
       "        [0.28377591],\n",
       "        [0.3630823 ],\n",
       "        [0.64591724],\n",
       "        [0.5707783 ]],\n",
       "\n",
       "       [[0.35609673],\n",
       "        [0.98651525],\n",
       "        [0.60577482],\n",
       "        [0.23722679],\n",
       "        [0.10178247],\n",
       "        [0.15285914],\n",
       "        [0.24595773],\n",
       "        [0.16068137],\n",
       "        [0.18656702],\n",
       "        [0.28509517]],\n",
       "\n",
       "       [[0.1733736 ],\n",
       "        [0.89676542],\n",
       "        [0.08023375],\n",
       "        [0.52451139],\n",
       "        [0.41039683],\n",
       "        [0.98237862],\n",
       "        [0.1120389 ],\n",
       "        [0.3978556 ],\n",
       "        [0.96947043],\n",
       "        [0.86550713]],\n",
       "\n",
       "       [[0.81707207],\n",
       "        [0.25790283],\n",
       "        [0.17088759],\n",
       "        [0.66864322],\n",
       "        [0.92937599],\n",
       "        [0.55676289],\n",
       "        [0.57161269],\n",
       "        [0.27997909],\n",
       "        [0.76949293],\n",
       "        [0.18704375]],\n",
       "\n",
       "       [[0.32367924],\n",
       "        [0.42543644],\n",
       "        [0.50761038],\n",
       "        [0.24240973],\n",
       "        [0.11483682],\n",
       "        [0.61062004],\n",
       "        [0.28863055],\n",
       "        [0.58123822],\n",
       "        [0.15436272],\n",
       "        [0.4811401 ]],\n",
       "\n",
       "       [[0.53258943],\n",
       "        [0.05182354],\n",
       "        [0.33660428],\n",
       "        [0.13441468],\n",
       "        [0.06337497],\n",
       "        [0.98996023],\n",
       "        [0.32235384],\n",
       "        [0.80987445],\n",
       "        [0.25464065],\n",
       "        [0.68150272]],\n",
       "\n",
       "       [[0.76022786],\n",
       "        [0.59563874],\n",
       "        [0.47157619],\n",
       "        [0.41184091],\n",
       "        [0.34886827],\n",
       "        [0.92952914],\n",
       "        [0.83061941],\n",
       "        [0.96502691],\n",
       "        [0.12429722],\n",
       "        [0.73086748]],\n",
       "\n",
       "       [[0.93834046],\n",
       "        [0.18123307],\n",
       "        [0.06649627],\n",
       "        [0.74112065],\n",
       "        [0.57447311],\n",
       "        [0.84182878],\n",
       "        [0.13977238],\n",
       "        [0.79526731],\n",
       "        [0.20162732],\n",
       "        [0.16365594]],\n",
       "\n",
       "       [[0.1642658 ],\n",
       "        [0.81457472],\n",
       "        [0.66519722],\n",
       "        [0.52306542],\n",
       "        [0.35883048],\n",
       "        [0.87720054],\n",
       "        [0.39244511],\n",
       "        [0.81659944],\n",
       "        [0.43913491],\n",
       "        [0.37694443]],\n",
       "\n",
       "       [[0.46267979],\n",
       "        [0.30137787],\n",
       "        [0.74760938],\n",
       "        [0.50272039],\n",
       "        [0.2322127 ],\n",
       "        [0.89957457],\n",
       "        [0.38389122],\n",
       "        [0.54355286],\n",
       "        [0.90647211],\n",
       "        [0.624238  ]],\n",
       "\n",
       "       [[0.11689804],\n",
       "        [0.93983212],\n",
       "        [0.62770805],\n",
       "        [0.33490561],\n",
       "        [0.13927207],\n",
       "        [0.79402519],\n",
       "        [0.62007276],\n",
       "        [0.53346109],\n",
       "        [0.89389258],\n",
       "        [0.78859721]],\n",
       "\n",
       "       [[0.15167488],\n",
       "        [0.31172207],\n",
       "        [0.24848914],\n",
       "        [0.74394629],\n",
       "        [0.03353243],\n",
       "        [0.56988968],\n",
       "        [0.76245869],\n",
       "        [0.87676564],\n",
       "        [0.34208175],\n",
       "        [0.8212573 ]],\n",
       "\n",
       "       [[0.11063174],\n",
       "        [0.84645229],\n",
       "        [0.12748866],\n",
       "        [0.39728729],\n",
       "        [0.79729537],\n",
       "        [0.14991743],\n",
       "        [0.2292514 ],\n",
       "        [0.72225257],\n",
       "        [0.72003654],\n",
       "        [0.64114763]],\n",
       "\n",
       "       [[0.69394844],\n",
       "        [0.54272444],\n",
       "        [0.25179906],\n",
       "        [0.34569599],\n",
       "        [0.18159772],\n",
       "        [0.90845056],\n",
       "        [0.58339179],\n",
       "        [0.40085142],\n",
       "        [0.4620058 ],\n",
       "        [0.94728334]],\n",
       "\n",
       "       [[0.1533514 ],\n",
       "        [0.58622983],\n",
       "        [0.50588868],\n",
       "        [0.61145424],\n",
       "        [0.01811018],\n",
       "        [0.87212391],\n",
       "        [0.93211828],\n",
       "        [0.56513318],\n",
       "        [0.69665082],\n",
       "        [0.92249938]],\n",
       "\n",
       "       [[0.70723863],\n",
       "        [0.15253904],\n",
       "        [0.57628836],\n",
       "        [0.60671505],\n",
       "        [0.42413067],\n",
       "        [0.73644424],\n",
       "        [0.93436701],\n",
       "        [0.92556851],\n",
       "        [0.45083937],\n",
       "        [0.11323805]],\n",
       "\n",
       "       [[0.9848412 ],\n",
       "        [0.83889809],\n",
       "        [0.12466268],\n",
       "        [0.92084188],\n",
       "        [0.86989636],\n",
       "        [0.51883806],\n",
       "        [0.59127544],\n",
       "        [0.3990027 ],\n",
       "        [0.05476164],\n",
       "        [0.33519724]],\n",
       "\n",
       "       [[0.80285345],\n",
       "        [0.00463202],\n",
       "        [0.33349917],\n",
       "        [0.39816869],\n",
       "        [0.5373956 ],\n",
       "        [0.91985562],\n",
       "        [0.34634599],\n",
       "        [0.3469532 ],\n",
       "        [0.73750125],\n",
       "        [0.45221794]],\n",
       "\n",
       "       [[0.22460482],\n",
       "        [0.45243952],\n",
       "        [0.14085702],\n",
       "        [0.17638699],\n",
       "        [0.49836777],\n",
       "        [0.41892545],\n",
       "        [0.9148459 ],\n",
       "        [0.3623939 ],\n",
       "        [0.58058835],\n",
       "        [0.63226429]],\n",
       "\n",
       "       [[0.01309446],\n",
       "        [0.66353737],\n",
       "        [0.17803597],\n",
       "        [0.96107032],\n",
       "        [0.14866273],\n",
       "        [0.41462412],\n",
       "        [0.08534967],\n",
       "        [0.99687425],\n",
       "        [0.50219501],\n",
       "        [0.59538502]],\n",
       "\n",
       "       [[0.06707648],\n",
       "        [0.74996047],\n",
       "        [0.20990559],\n",
       "        [0.89805429],\n",
       "        [0.20513964],\n",
       "        [0.19068772],\n",
       "        [0.03654967],\n",
       "        [0.47206695],\n",
       "        [0.56484113],\n",
       "        [0.06570864]],\n",
       "\n",
       "       [[0.77552762],\n",
       "        [0.45328883],\n",
       "        [0.52439027],\n",
       "        [0.44076275],\n",
       "        [0.40076306],\n",
       "        [0.55964033],\n",
       "        [0.15524025],\n",
       "        [0.18192813],\n",
       "        [0.86178562],\n",
       "        [0.94611546]],\n",
       "\n",
       "       [[0.37330932],\n",
       "        [0.27074467],\n",
       "        [0.64399954],\n",
       "        [0.40873417],\n",
       "        [0.02538636],\n",
       "        [0.1561526 ],\n",
       "        [0.71597223],\n",
       "        [0.65892394],\n",
       "        [0.02709599],\n",
       "        [0.22197216]],\n",
       "\n",
       "       [[0.2310748 ],\n",
       "        [0.67189274],\n",
       "        [0.01971054],\n",
       "        [0.10410858],\n",
       "        [0.79991609],\n",
       "        [0.17854466],\n",
       "        [0.65274611],\n",
       "        [0.23818278],\n",
       "        [0.09944139],\n",
       "        [0.24317219]],\n",
       "\n",
       "       [[0.72226693],\n",
       "        [0.85569647],\n",
       "        [0.83021986],\n",
       "        [0.39718353],\n",
       "        [0.66808514],\n",
       "        [0.2049843 ],\n",
       "        [0.29314773],\n",
       "        [0.89633582],\n",
       "        [0.01300192],\n",
       "        [0.08550853]],\n",
       "\n",
       "       [[0.20788626],\n",
       "        [0.0265322 ],\n",
       "        [0.18143544],\n",
       "        [0.58304156],\n",
       "        [0.42142455],\n",
       "        [0.89267171],\n",
       "        [0.81744356],\n",
       "        [0.34181735],\n",
       "        [0.25942343],\n",
       "        [0.37969241]],\n",
       "\n",
       "       [[0.59029494],\n",
       "        [0.26806364],\n",
       "        [0.62414891],\n",
       "        [0.40941165],\n",
       "        [0.55204718],\n",
       "        [0.43612653],\n",
       "        [0.29446576],\n",
       "        [0.94845331],\n",
       "        [0.76360579],\n",
       "        [0.14011318]],\n",
       "\n",
       "       [[0.86846798],\n",
       "        [0.4874312 ],\n",
       "        [0.89455223],\n",
       "        [0.79985526],\n",
       "        [0.4252135 ],\n",
       "        [0.02246931],\n",
       "        [0.26867736],\n",
       "        [0.54163421],\n",
       "        [0.63347822],\n",
       "        [0.25788769]],\n",
       "\n",
       "       [[0.13935607],\n",
       "        [0.83493024],\n",
       "        [0.98440218],\n",
       "        [0.52569018],\n",
       "        [0.17167929],\n",
       "        [0.27230733],\n",
       "        [0.01839068],\n",
       "        [0.91429881],\n",
       "        [0.11775108],\n",
       "        [0.57651648]],\n",
       "\n",
       "       [[0.27405522],\n",
       "        [0.554178  ],\n",
       "        [0.65142039],\n",
       "        [0.8297418 ],\n",
       "        [0.20642127],\n",
       "        [0.01099583],\n",
       "        [0.13688563],\n",
       "        [0.90001864],\n",
       "        [0.87389008],\n",
       "        [0.5974131 ]],\n",
       "\n",
       "       [[0.60051686],\n",
       "        [0.66503667],\n",
       "        [0.17537128],\n",
       "        [0.91441195],\n",
       "        [0.41877052],\n",
       "        [0.38313853],\n",
       "        [0.51891771],\n",
       "        [0.04696597],\n",
       "        [0.16628337],\n",
       "        [0.73803362]],\n",
       "\n",
       "       [[0.08279867],\n",
       "        [0.60315211],\n",
       "        [0.24534911],\n",
       "        [0.38929561],\n",
       "        [0.28869374],\n",
       "        [0.35567272],\n",
       "        [0.71904591],\n",
       "        [0.29712172],\n",
       "        [0.56640464],\n",
       "        [0.4760504 ]],\n",
       "\n",
       "       [[0.66367117],\n",
       "        [0.93682974],\n",
       "        [0.7325721 ],\n",
       "        [0.21494038],\n",
       "        [0.03118314],\n",
       "        [0.26226404],\n",
       "        [0.59507793],\n",
       "        [0.05142581],\n",
       "        [0.49636625],\n",
       "        [0.59684285]],\n",
       "\n",
       "       [[0.33424389],\n",
       "        [0.7709122 ],\n",
       "        [0.10659825],\n",
       "        [0.07513778],\n",
       "        [0.72818876],\n",
       "        [0.49549132],\n",
       "        [0.6884024 ],\n",
       "        [0.43482734],\n",
       "        [0.24640203],\n",
       "        [0.81910232]],\n",
       "\n",
       "       [[0.79941588],\n",
       "        [0.69469647],\n",
       "        [0.27214514],\n",
       "        [0.59023067],\n",
       "        [0.3609739 ],\n",
       "        [0.09158207],\n",
       "        [0.91731358],\n",
       "        [0.13681863],\n",
       "        [0.95023735],\n",
       "        [0.44600577]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_case\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "199b9444-1b35-4902-a6ee-bc0c92684981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 3s 60ms/step - loss: 1.2713 - accuracy: 0.6162 - val_loss: 1.1193 - val_accuracy: 0.7097\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9461 - accuracy: 0.7054 - val_loss: 0.8097 - val_accuracy: 0.6882\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6744 - accuracy: 0.7135 - val_loss: 0.6870 - val_accuracy: 0.7742\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5377 - accuracy: 0.8081 - val_loss: 0.6419 - val_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4592 - accuracy: 0.8405 - val_loss: 0.5789 - val_accuracy: 0.7957\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4192 - accuracy: 0.8486 - val_loss: 0.5749 - val_accuracy: 0.8172\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3726 - accuracy: 0.8865 - val_loss: 0.4974 - val_accuracy: 0.8495\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3468 - accuracy: 0.8703 - val_loss: 0.4601 - val_accuracy: 0.8495\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.9000 - val_loss: 0.4444 - val_accuracy: 0.8710\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3151 - accuracy: 0.8865 - val_loss: 0.4202 - val_accuracy: 0.8495\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8966\n",
      "Test Loss: 0.3687, Test Accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load your labeled dataset from the Excel file\n",
    "# Replace 'new_data.xlsx' with the path to your new data file\n",
    "data = pd.read_excel('emg_data.xlsx')\n",
    "\n",
    "# Extract features (EMG_A0, EMG_A1) and labels\n",
    "X = data[['EMG_A0', 'EMG_A1']].values\n",
    "y = data['Label'].values\n",
    "\n",
    "# Encode categorical labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create sequences for the LSTM model\n",
    "sequence_length = 10  # Adjust this based on the length of sequences you want\n",
    "X_sequence = []\n",
    "y_sequence = []\n",
    "\n",
    "for i in range(len(X_scaled) - sequence_length + 1):\n",
    "    X_sequence.append(X_scaled[i:i+sequence_length, :])\n",
    "    y_sequence.append(y_encoded[i+sequence_length-1])\n",
    "\n",
    "X_sequence = np.array(X_sequence)\n",
    "y_sequence = np.array(y_sequence)\n",
    "\n",
    "# Convert labels to one-hot encoding for multi-class classification\n",
    "y_sequence_onehot = to_categorical(y_sequence, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sequence, y_sequence_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(sequence_length, X_scaled.shape[1]), return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=len(label_encoder.classes_), activation='softmax'))  # Multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save the trained model for later use\n",
    "model.save('trained_model_multiclass.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8e613ac-a773-4737-a34c-c00daddcfb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 3ms/step\n",
      "[[0.52633995 0.06748138 0.40191683 0.00426186]\n",
      " [0.31311753 0.07013524 0.6127049  0.00404233]\n",
      " [0.19167757 0.06251336 0.741874   0.00393511]\n",
      " ...\n",
      " [0.01352136 0.01929396 0.0094422  0.9577424 ]\n",
      " [0.01070263 0.0143078  0.00731391 0.9676756 ]\n",
      " [0.00864981 0.0109062  0.00587644 0.9745676 ]]\n",
      "Predictions:\n",
      "[[1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have a trained model named 'model'\n",
    "\n",
    "# Load new data for testing\n",
    "# Replace 'new_data.xlsx' with the path to your new data file\n",
    "new_data = pd.read_excel('new_data.xlsx')\n",
    "\n",
    "# Extract features (EMG_A0, EMG_A1) from the new data\n",
    "X_new = new_data[['EMG_A0', 'EMG_A1']].values\n",
    "\n",
    "# Normalize the features using the same scaler used during training\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Create sequences for the LSTM model\n",
    "X_new_sequence = []\n",
    "\n",
    "for i in range(len(X_new_scaled) - sequence_length + 1):\n",
    "    X_new_sequence.append(X_new_scaled[i:i+sequence_length, :])\n",
    "\n",
    "X_new_sequence = np.array(X_new_sequence)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(X_new_sequence)\n",
    "print(predictions)\n",
    "# Convert predictions to binary classes (0 or 1) based on a threshold\n",
    "threshold = 0.5  # Adjust as needed\n",
    "binary_predictions = (predictions > threshold).astype(int)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions:\")\n",
    "print(binary_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6e6ad62-2f42-4cd2-a73f-e9cfc169c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2198f735-2140-4b4b-bcc6-8b87444beba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 6s 90ms/step - loss: 1.2706 - accuracy: 0.6784 - val_loss: 1.1257 - val_accuracy: 0.7742\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.9686 - accuracy: 0.7676 - val_loss: 0.8509 - val_accuracy: 0.7634\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.7676 - val_loss: 0.7158 - val_accuracy: 0.7527\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5458 - accuracy: 0.7946 - val_loss: 0.6559 - val_accuracy: 0.7849\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4742 - accuracy: 0.8243 - val_loss: 0.6195 - val_accuracy: 0.8065\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.8486 - val_loss: 0.5579 - val_accuracy: 0.8172\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3955 - accuracy: 0.8486 - val_loss: 0.5232 - val_accuracy: 0.8280\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3560 - accuracy: 0.8838 - val_loss: 0.4889 - val_accuracy: 0.8387\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3408 - accuracy: 0.8757 - val_loss: 0.4450 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3182 - accuracy: 0.8973 - val_loss: 0.5074 - val_accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load your labeled dataset from the Excel file\n",
    "# Replace 'emg_data.xlsx' with the path to your data file\n",
    "data = pd.read_excel('emg_data.xlsx')\n",
    "\n",
    "# Check if the dataset has at least one sample\n",
    "if data.shape[0] == 0:\n",
    "    print(\"Error: The dataset does not contain any samples.\")\n",
    "else:\n",
    "    # Extract features (EMG_A0, EMG_A1) and labels\n",
    "    X = data[['EMG_A0', 'EMG_A1']].values\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Check if there are samples to fit the StandardScaler\n",
    "    if X.shape[0] > 0:\n",
    "        # Encode categorical labels into numerical values\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "        # Save label encoder classes for later use\n",
    "        np.save('label_encoder_classes.npy', label_encoder.classes_)\n",
    "\n",
    "        # Normalize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Create sequences for the LSTM model\n",
    "        sequence_length = 10  # Adjust this based on the length of sequences you want\n",
    "        X_sequence = []\n",
    "        y_sequence = []\n",
    "\n",
    "        for i in range(len(X_scaled) - sequence_length + 1):\n",
    "            X_sequence.append(X_scaled[i:i + sequence_length, :])\n",
    "            y_sequence.append(y_encoded[i + sequence_length - 1])\n",
    "\n",
    "        X_sequence = np.array(X_sequence)\n",
    "        y_sequence = np.array(y_sequence)\n",
    "\n",
    "        # Convert labels to one-hot encoding for multi-class classification\n",
    "        num_classes = len(np.unique(y_encoded))  # Number of unique classes\n",
    "        y_sequence_onehot = to_categorical(y_sequence, num_classes=num_classes)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_sequence, y_sequence_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Define the LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=50, input_shape=(sequence_length, X_scaled.shape[1]), return_sequences=True))\n",
    "        model.add(LSTM(units=50))\n",
    "        model.add(Dense(units=num_classes, activation='softmax'))  # Adjusted to use num_classes\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "        # Save the trained model for later use\n",
    "        model.save('trained_model_multiclass.h5')\n",
    "    else:\n",
    "        print(\"Error: No samples to fit the StandardScaler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b629fd0-98d2-484e-b533-d631796b8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        41\n",
      "           1       0.64      0.67      0.65        27\n",
      "           2       0.88      0.84      0.86        25\n",
      "           3       0.74      0.80      0.77        25\n",
      "\n",
      "    accuracy                           0.82       118\n",
      "   macro avg       0.81      0.81      0.81       118\n",
      "weighted avg       0.83      0.82      0.82       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load your sample data from Excel\n",
    "data = pd.read_excel(\"emg_data.xlsx\")\n",
    "\n",
    "# Separate features (EMG_A0 and EMG_A1) and labels (Label)\n",
    "X = data[['EMG_A0', 'EMG_A1']]\n",
    "y = data['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(rf_model, \"random_forest_model.joblib\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "daaa93f4-be81-462b-8d68-2a732c50909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels for new data:\n",
      "[0 2 2 2 0 3 2 1 3 0 1 0 0 0 2 3 2 0 2 2 1 1 2 2 2 3 2 2 0 0 3 1 1 0 3 2 0\n",
      " 0 1 0 2 1 0 0 1 2 2 3 1 2 1 1 0 0 3 3 2 0 1 0 3 1 0 2 2 0 0 2 3 0 1 3 2 1\n",
      " 0 0 3 0 0 3 0 1 0 0 0 3 0 2 0 2 0 2 1 3 1 2 1 2 2 1 0 0 1 2 3 3 1 1 0 3 3\n",
      " 2 0 0 1 3 1 1 1 3 1 3 3 0 0 0 0 2 0 0 1 1 2 0 1 1 2 3 3 2 3 3 2 2 3 2 0 3\n",
      " 1 1 3 0 1 0 2 2 2 3 0 2 0 0 3 3 3 0 1 1 0 2 3 3 3 3 0 3 0 1 2 2 0 0 2 1 3\n",
      " 1 0 3 1 0 0 1 2 3 0 2 2 0 3 3 0 3 0 0 1 0 0 1 2 3 3 2 3 2 3 1 0 0 1 3 1 0\n",
      " 0 2 0 2 0 2 0 3 0 1 0 0 1 2 2 2 1 1 0 2 0 2 3 0 1 1 2 2 3 1 2 0 1 1 0 0 0\n",
      " 3 2 2 1 0 0 2 0 3 0 2 3 1 0 1 0 1 0 3 2 2 2 3 1 2 1 2 0 0 1 0 1 1 3 0 0 1\n",
      " 1 2 1 2 2 2 1 0 0 1 2 3 3 2 2 0 2 0 2 0 0 1 3 3 3 1 1 0 3 3 0 0 1 0 2 3 2\n",
      " 1 0 2 1 3 1 2 1 1 2 1 2 1 0 0 2 0 0 3 3 1 2 2 2 1 0 1 0 3 2 0 2 0 3 0 1 2\n",
      " 0 2 1 0 2 2 0 0 1 1 3 3 0 3 1 0 3 0 0 0 0 0 1 0 3 2 2 0 1 3 2 1 3 2 0 3 2\n",
      " 3 3 1 3 0 2 2 1 0 2 0 0 2 1 2 0 2 2 3 3 0 2 0 0 0 2 0 0 0 3 0 1 3 1 1 1 2\n",
      " 1 3 1 2 0 2 0 3 2 2 2 0 0 3 1 2 1 1 0 3 2 0 0 2 1 0 3 0 2 0 1 0 2 2 2 0 1\n",
      " 2 2 3 0 3 0 0 0 2 2 0 3 3 0 0 2 3 3 2 3 3 2 0 0 1 3 2 2 0 3 3 3 3 0 2 0 0\n",
      " 3 0 2 2 0 3 1 2 0 0 0 2 0 3 3 2 0 2 2 1 3 0 2 0 0 1 3 1 1 2 1 2 2 0 0 0 3\n",
      " 3 0 0 0 2 0 1 0 1 2 3 0 2 1 0 3 0 3 0 2 3 3 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"random_forest_model.joblib\")\n",
    "data = pd.read_excel(\"new_data.xlsx\")\n",
    "\n",
    "# Assuming 'new_data' is your new dataset with columns 'EMG_A0' and 'EMG_A1'\n",
    "new_predictions = loaded_model.predict(data[['EMG_A0', 'EMG_A1']])\n",
    "\n",
    "# Display the predicted labels\n",
    "print(\"Predicted Labels for new data:\")\n",
    "print(new_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6f361-bafc-4b51-84b5-e52440f1178b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
